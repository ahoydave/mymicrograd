{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Game Plan\n",
    "* MLP\n",
    "* Predict next letter from last x letters\n",
    "* Layers - embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from typing import Tuple\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marshall the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_letters = 3\n",
    "start_char = '^'\n",
    "end_char = '$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'olivia', 'ava', 'isabella', 'sophia']\n"
     ]
    }
   ],
   "source": [
    "with open('names.txt', 'r') as file:\n",
    "    names = [line.strip() for line in file.readlines()]\n",
    "print(names[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h', 'e', 'l', 'l', 'o', 't', 'h', 'e', 'r', 'e']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters = set(reduce(lambda a,b: a + b, names) + start_char + end_char)\n",
    "itol = dict(enumerate(letters))\n",
    "ltoi = dict([(l, i) for (i, l) in itol.items()])\n",
    "list(map(lambda l: itol[ltoi[l]], 'hellothere'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_examples(name: str) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    name = start_char * context_letters + name + end_char\n",
    "    name_pieces = [name[i: i+context_letters+1] for i in range(len(name)-context_letters)]\n",
    "    def indexify(l_list: list[str]) -> torch.tensor:\n",
    "        return torch.tensor(list(map(lambda l: ltoi[l], l_list)))\n",
    "    return torch.stack(list(map(indexify, name_pieces)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24, 24, 24, 18],\n",
       "        [24, 24, 18,  1],\n",
       "        [24, 18,  1,  6],\n",
       "        [18,  1,  6,  2],\n",
       "        [ 1,  6,  2,  3]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_to_examples('dave')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24, 24, 24,  2],\n",
      "        [24, 24,  2,  0]])\n",
      "tensor([[24, 24, 24],\n",
      "        [24, 24,  2]])\n",
      "tensor([2, 0])\n"
     ]
    }
   ],
   "source": [
    "examples = list(map(name_to_examples, names))\n",
    "examples = torch.cat(examples)\n",
    "x = examples[:, :-1]\n",
    "y = examples[:, -1]\n",
    "print(examples[:2])\n",
    "print(x[:2])\n",
    "print(y[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_one_hot = nn.functional.one_hot(x, num_classes=len(letters))\n",
    "x_one_hot = x_one_hot.float()\n",
    "x_one_hot = x_one_hot.view(x_one_hot.size(0), -1)\n",
    "x_one_hot[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMLP(nn.Module):\n",
    "    def __init__(self, dict_size, context_size, embedding_size):\n",
    "        super().__init__()\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(dict_size * context_size, embedding_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(embedding_size, dict_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyMLP(\n",
      "  (linear_stack): Sequential(\n",
      "    (0): Linear(in_features=84, out_features=30, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=30, out_features=28, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MyMLP(len(letters), context_letters, 30)\n",
    "print(model)\n",
    "output = model(x_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0720,  0.0284,  0.0749, -0.0220,  0.0160, -0.0806,  0.0462,  0.1029,\n",
       "          0.1939,  0.0630, -0.1704, -0.1799,  0.1714,  0.1385,  0.0494, -0.1409,\n",
       "          0.0757,  0.1016,  0.2202,  0.0439, -0.1749, -0.0408,  0.0902,  0.2051,\n",
       "          0.0963,  0.0976, -0.0517,  0.0369],\n",
       "        [-0.0922, -0.0750,  0.0398, -0.0942,  0.0486,  0.0283,  0.0933,  0.0460,\n",
       "          0.1685,  0.1499, -0.2231, -0.1190,  0.1185,  0.0377,  0.0456, -0.1873,\n",
       "          0.0585,  0.0776,  0.1892,  0.0165, -0.1636, -0.0451, -0.0117,  0.1514,\n",
       "          0.1046,  0.0754, -0.0033,  0.0542]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([15])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[24, 24, 24],\n",
       "        [24, 24, 24],\n",
       "        [24, 24, 24],\n",
       "        [24, 24, 24],\n",
       "        [24, 24, 24]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with word beginnings\n",
    "num_gen = 5\n",
    "gen = torch.tensor([ltoi[start_char]] * context_letters * num_gen, dtype=int)\n",
    "print(gen.size())\n",
    "gen = gen.view(num_gen, context_letters)\n",
    "print(gen.size())\n",
    "print(gen.view(-1).size())\n",
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 17])\n"
     ]
    }
   ],
   "source": [
    "print(gen.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['^', 'i', 'r', 'a', 'm']\n"
     ]
    }
   ],
   "source": [
    "gen_one_hot = nn.functional.one_hot(gen[:,-context_letters:].reshape(-1, 1), num_classes=len(letters)).float()\n",
    "gen_one_hot = gen_one_hot.view(num_gen, context_letters * len(letters))\n",
    "gen_output = model(gen_one_hot)\n",
    "gen_probs = nn.functional.softmax(gen_output, dim=1)\n",
    "gen_samples = torch.multinomial(gen_probs, 1)\n",
    "print([itol[sample.item()] for sample in gen_samples])\n",
    "gen = torch.cat([gen, gen_samples], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24, 24, 24, 23],\n",
       "        [24, 24, 24, 13],\n",
       "        [24, 24, 24,  8],\n",
       "        [24, 24, 24, 22],\n",
       "        [24, 24, 24,  8]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[24, 24, 24, 22],\n",
       "        [24, 24, 24, 18],\n",
       "        [24, 24, 24,  5],\n",
       "        [24, 24, 24,  4],\n",
       "        [24, 24, 24,  6]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12],\n",
      "        [ 0],\n",
      "        [24],\n",
      "        ...,\n",
      "        [ 2],\n",
      "        [ 7],\n",
      "        [17]])\n"
     ]
    }
   ],
   "source": [
    "probabilities = nn.functional.softmax(output, dim=1)\n",
    "\n",
    "# Sample from the categories\n",
    "sample = torch.multinomial(probabilities, 1)\n",
    "\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
