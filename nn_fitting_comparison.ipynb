{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "# not sure if there is an easier way to reload the nn module when I change it\n",
    "import nn\n",
    "importlib.reload(sys.modules['nn'])\n",
    "from nn import Value, SimpleNN\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as py_nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from micrograd.nn import MLP\n",
    "from micrograd.engine import Value as KValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_vec(size):\n",
    "    return [Value(random.uniform(-1, 1)) for _ in range(size)] # Now using a Value here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_values(vec):\n",
    "    s = Value(0)\n",
    "    for v in vec:\n",
    "        s += v\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(net: SimpleNN, example: tuple[list[float], float]):\n",
    "    return (net.forward(example[0]) - example[1]).sq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_fn(learning_rate: float):\n",
    "    def update(w: Value):\n",
    "        return Value(w.data - learning_rate * w.grad)\n",
    "    return update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([Value(label=, data=0.08426491671592773), Value(label=, data=-0.8395857167394767)], Value(label=, data=-0.755320800023549))\n",
      "Value(label=, data=-0.755320800023549)\n"
     ]
    }
   ],
   "source": [
    "def generate_sum_fn_training_data(num_examples, input_size):\n",
    "    training_data = [rand_vec(input_size) for _ in range(num_examples)]\n",
    "    training_data = [(x, sum_values(x)) for x in training_data]\n",
    "    return training_data\n",
    "\n",
    "training_data = generate_sum_fn_training_data(10, 2)\n",
    "print(training_data[0])\n",
    "print(sum_values(training_data[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch model for comparison\n",
    "\n",
    "class PTNet(py_nn.Module):\n",
    "    def __init__(self, layer_sizes: list[int]):\n",
    "        super(PTNet, self).__init__()\n",
    "        layers = []\n",
    "        assert len(layer_sizes) > 0, \"One layer needed for input\"\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            layers.append(py_nn.Linear(layer_sizes[i], layer_sizes[i+1]))\n",
    "            layers.append(py_nn.ReLU())\n",
    "        layers.append(py_nn.Linear(layer_sizes[-1], 1))\n",
    "        self.model = py_nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(data=0.41063906520924115, grad=0)\n"
     ]
    }
   ],
   "source": [
    "def local_scope():\n",
    "    nn = MLP(5, [1])\n",
    "    print(nn([random.random() for _ in range(5)]))\n",
    "local_scope()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_sum_experiment(input_size, learning_rate, training_steps, training_data_size, layer_sizes: list[int]):\n",
    "    training_data = generate_sum_fn_training_data(training_data_size, input_size)\n",
    "    my_nn = SimpleNN(input_size, layer_sizes)\n",
    "    pt_nn = PTNet([input_size] + layer_sizes)\n",
    "\n",
    "    criterion = py_nn.MSELoss()\n",
    "    optimizer = optim.SGD(pt_nn.parameters(), lr=learning_rate)\n",
    "\n",
    "    x_train = torch.rand(training_data_size, input_size)\n",
    "    y_train = x_train.sum(dim=1, keepdim=True)\n",
    "\n",
    "    my_training_data = []\n",
    "    for inputs, result in zip(x_train, y_train):\n",
    "        my_training_data.append([[Value(v) for v in inputs.tolist()], Value(result.item())])\n",
    "\n",
    "    k_training_data = []\n",
    "    for inputs, result in zip(x_train, y_train):\n",
    "        k_training_data.append([[v for v in inputs.tolist()], KValue(result.item())])\n",
    "\n",
    "    print(x_train[0])\n",
    "    print(my_training_data[0][0])\n",
    "    print(y_train[0])\n",
    "    print(my_training_data[0][1])\n",
    "\n",
    "    k_nn = MLP(input_size, layer_sizes + [1])\n",
    "\n",
    "    print(f\"KNN check {k_nn(k_training_data[0][0])}\")\n",
    "\n",
    "    my_losses = []\n",
    "    k_losses = []\n",
    "    pt_losses = []\n",
    "    for step in range(training_steps):\n",
    "        \n",
    "        # For the two scarlar based models, loop through the training data\n",
    "        my_sum_loss = 0.0\n",
    "        k_sum_loss = 0.0\n",
    "        for example in my_training_data:\n",
    "            my_current_loss = loss(my_nn, example)\n",
    "            my_sum_loss += my_current_loss.data\n",
    "            my_nn.backward(update_fn(learning_rate), my_current_loss)\n",
    "\n",
    "        for example in k_training_data:\n",
    "            k_nn.zero_grad()\n",
    "            k_current_loss = (example[1] - k_nn(example[0]))**2\n",
    "            k_sum_loss += k_current_loss.data\n",
    "            k_current_loss.backward()\n",
    "            for param in k_nn.parameters():\n",
    "                param.data = param.data - learning_rate * param.grad\n",
    "        \n",
    "        my_losses.append(my_sum_loss / len(x_train))\n",
    "        print(f\"MyNN: Epoch {step+1}, Loss: {my_losses[-1]}\")\n",
    "\n",
    "        k_losses.append(k_sum_loss / len(x_train))\n",
    "        print(f\"KNN: Epoch {step+1}, Loss: {k_losses[-1]}\")\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = pt_nn(x_train)\n",
    "        pt_loss = criterion(outputs, y_train)\n",
    "        pt_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch {step+1}, Loss: {pt_loss.item()}')\n",
    "        pt_losses.append(pt_loss.item())\n",
    "        \n",
    "    plt.plot(my_losses[-5:], label=\"my_losses\")\n",
    "    plt.plot(k_losses[-5:], label=\"k_losses\")\n",
    "    plt.plot(pt_losses[-5:], label=\"py_losses\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8333, 0.3392, 0.2870, 0.1524, 0.6411])\n",
      "[Value(label=, data=0.8333094716072083), Value(label=, data=0.3392459750175476), Value(label=, data=0.2870160937309265), Value(label=, data=0.1523873209953308), Value(label=, data=0.6410520076751709)]\n",
      "tensor([2.2530])\n",
      "Value(label=, data=2.2530109882354736)\n",
      "KNN check Value(data=0.8506127327111688, grad=0)\n",
      "MyNN: Epoch 1, Loss: 0.09751449250275868\n",
      "KNN: Epoch 1, Loss: 0.07157635102330166\n",
      "Epoch 1, Loss: 9.326949119567871\n",
      "MyNN: Epoch 2, Loss: 0.0008913402167919898\n",
      "KNN: Epoch 2, Loss: 0.0041885607007942196\n",
      "Epoch 2, Loss: 8.643608093261719\n",
      "MyNN: Epoch 3, Loss: 0.00031515368270600055\n",
      "KNN: Epoch 3, Loss: 0.0017835688891710793\n",
      "Epoch 3, Loss: 8.045482635498047\n",
      "MyNN: Epoch 4, Loss: 0.00018194456874563727\n",
      "KNN: Epoch 4, Loss: 0.0009895940017846875\n",
      "Epoch 4, Loss: 7.511300086975098\n",
      "MyNN: Epoch 5, Loss: 0.00012183210616938379\n",
      "KNN: Epoch 5, Loss: 0.000648120900818183\n",
      "Epoch 5, Loss: 7.025822162628174\n",
      "MyNN: Epoch 6, Loss: 9.010210532815727e-05\n",
      "KNN: Epoch 6, Loss: 0.0004666783199278265\n",
      "Epoch 6, Loss: 6.578319549560547\n",
      "MyNN: Epoch 7, Loss: 7.03826977666441e-05\n",
      "KNN: Epoch 7, Loss: 0.0003614568791604158\n",
      "Epoch 7, Loss: 6.160890579223633\n",
      "MyNN: Epoch 8, Loss: 5.5996010513651395e-05\n",
      "KNN: Epoch 8, Loss: 0.0002960553103938001\n",
      "Epoch 8, Loss: 5.767299652099609\n",
      "MyNN: Epoch 9, Loss: 4.4382706141070655e-05\n",
      "KNN: Epoch 9, Loss: 0.000251786303809547\n",
      "Epoch 9, Loss: 5.393396377563477\n",
      "MyNN: Epoch 10, Loss: 3.459924053411272e-05\n",
      "KNN: Epoch 10, Loss: 0.0002193745121422664\n",
      "Epoch 10, Loss: 5.035866737365723\n",
      "MyNN: Epoch 11, Loss: 2.7448196297795712e-05\n",
      "KNN: Epoch 11, Loss: 0.00019431258812948143\n",
      "Epoch 11, Loss: 4.692309379577637\n",
      "MyNN: Epoch 12, Loss: 2.2044400009007025e-05\n",
      "KNN: Epoch 12, Loss: 0.0001739895487149945\n",
      "Epoch 12, Loss: 4.361095905303955\n",
      "MyNN: Epoch 13, Loss: 1.7922365713489523e-05\n",
      "KNN: Epoch 13, Loss: 0.00015700933556993482\n",
      "Epoch 13, Loss: 4.041146755218506\n",
      "MyNN: Epoch 14, Loss: 1.4664352011094722e-05\n",
      "KNN: Epoch 14, Loss: 0.00014233475950060898\n",
      "Epoch 14, Loss: 3.731916666030884\n",
      "MyNN: Epoch 15, Loss: 1.2063309238322328e-05\n",
      "KNN: Epoch 15, Loss: 0.00012956506588598254\n",
      "Epoch 15, Loss: 3.4332034587860107\n",
      "MyNN: Epoch 16, Loss: 9.977502141496674e-06\n",
      "KNN: Epoch 16, Loss: 0.00011841032947860652\n",
      "Epoch 16, Loss: 3.1452159881591797\n",
      "MyNN: Epoch 17, Loss: 8.289527557597704e-06\n",
      "KNN: Epoch 17, Loss: 0.00010870206014376543\n",
      "Epoch 17, Loss: 2.8684377670288086\n",
      "MyNN: Epoch 18, Loss: 6.922864076620468e-06\n",
      "KNN: Epoch 18, Loss: 0.00010019835508512786\n",
      "Epoch 18, Loss: 2.6035451889038086\n",
      "MyNN: Epoch 19, Loss: 5.813999187612989e-06\n",
      "KNN: Epoch 19, Loss: 9.265656260504589e-05\n",
      "Epoch 19, Loss: 2.3513541221618652\n",
      "MyNN: Epoch 20, Loss: 4.904911112449435e-06\n",
      "KNN: Epoch 20, Loss: 8.573702780704423e-05\n",
      "Epoch 20, Loss: 2.1127219200134277\n",
      "MyNN: Epoch 21, Loss: 4.16368311836566e-06\n",
      "KNN: Epoch 21, Loss: 7.950805356153891e-05\n",
      "Epoch 21, Loss: 1.888506293296814\n",
      "MyNN: Epoch 22, Loss: 3.5499908330549114e-06\n",
      "KNN: Epoch 22, Loss: 7.385685836093773e-05\n",
      "Epoch 22, Loss: 1.6794341802597046\n",
      "MyNN: Epoch 23, Loss: 3.0368361314550894e-06\n",
      "KNN: Epoch 23, Loss: 6.867484692468036e-05\n",
      "Epoch 23, Loss: 1.4860974550247192\n",
      "MyNN: Epoch 24, Loss: 2.607298019196695e-06\n",
      "KNN: Epoch 24, Loss: 6.403926836643356e-05\n",
      "Epoch 24, Loss: 1.3088797330856323\n",
      "MyNN: Epoch 25, Loss: 2.2473591229857194e-06\n",
      "KNN: Epoch 25, Loss: 5.983863825045214e-05\n",
      "Epoch 25, Loss: 1.147926926612854\n",
      "MyNN: Epoch 26, Loss: 1.9453962728247e-06\n",
      "KNN: Epoch 26, Loss: 5.609679126474268e-05\n",
      "Epoch 26, Loss: 1.0031228065490723\n",
      "MyNN: Epoch 27, Loss: 1.691355814263443e-06\n",
      "KNN: Epoch 27, Loss: 5.2757679074550616e-05\n",
      "Epoch 27, Loss: 0.8740845918655396\n",
      "MyNN: Epoch 28, Loss: 1.4760916921522566e-06\n",
      "KNN: Epoch 28, Loss: 4.968414835108376e-05\n",
      "Epoch 28, Loss: 0.7601969242095947\n",
      "MyNN: Epoch 29, Loss: 1.293154224168324e-06\n",
      "KNN: Epoch 29, Loss: 4.68416557415147e-05\n",
      "Epoch 29, Loss: 0.660638689994812\n",
      "MyNN: Epoch 30, Loss: 1.1374295581308045e-06\n",
      "KNN: Epoch 30, Loss: 4.420764883811776e-05\n",
      "Epoch 30, Loss: 0.5744192600250244\n",
      "MyNN: Epoch 31, Loss: 1.0040221945392975e-06\n",
      "KNN: Epoch 31, Loss: 4.1786898789854496e-05\n",
      "Epoch 31, Loss: 0.5004242658615112\n",
      "MyNN: Epoch 32, Loss: 8.890325118373816e-07\n",
      "KNN: Epoch 32, Loss: 3.9559209359727036e-05\n",
      "Epoch 32, Loss: 0.4374734163284302\n",
      "MyNN: Epoch 33, Loss: 7.897658521778204e-07\n",
      "KNN: Epoch 33, Loss: 3.750591290526037e-05\n",
      "Epoch 33, Loss: 0.3843616247177124\n",
      "MyNN: Epoch 34, Loss: 7.03935846323215e-07\n",
      "KNN: Epoch 34, Loss: 3.564159918781303e-05\n",
      "Epoch 34, Loss: 0.33990123867988586\n",
      "MyNN: Epoch 35, Loss: 6.296016705557867e-07\n",
      "KNN: Epoch 35, Loss: 3.398476784333569e-05\n",
      "Epoch 35, Loss: 0.30295446515083313\n",
      "MyNN: Epoch 36, Loss: 5.651350648630227e-07\n",
      "KNN: Epoch 36, Loss: 3.2435698266931394e-05\n",
      "Epoch 36, Loss: 0.2724559009075165\n",
      "MyNN: Epoch 37, Loss: 5.087926767446989e-07\n",
      "KNN: Epoch 37, Loss: 3.0991837344878096e-05\n",
      "Epoch 37, Loss: 0.24743236601352692\n",
      "MyNN: Epoch 38, Loss: 4.5941275214746027e-07\n",
      "KNN: Epoch 38, Loss: 2.9645390939218543e-05\n",
      "Epoch 38, Loss: 0.22701212763786316\n",
      "MyNN: Epoch 39, Loss: 4.160679115727043e-07\n",
      "KNN: Epoch 39, Loss: 2.8387321865725876e-05\n",
      "Epoch 39, Loss: 0.21042785048484802\n",
      "MyNN: Epoch 40, Loss: 3.7796158806977923e-07\n",
      "KNN: Epoch 40, Loss: 2.7211590730976774e-05\n",
      "Epoch 40, Loss: 0.19701293110847473\n",
      "MyNN: Epoch 41, Loss: 3.444087803660879e-07\n",
      "KNN: Epoch 41, Loss: 2.611068628192776e-05\n",
      "Epoch 41, Loss: 0.18619683384895325\n",
      "MyNN: Epoch 42, Loss: 3.148090039708842e-07\n",
      "KNN: Epoch 42, Loss: 2.5078490260658475e-05\n",
      "Epoch 42, Loss: 0.17749746143817902\n",
      "MyNN: Epoch 43, Loss: 2.8848795050275073e-07\n",
      "KNN: Epoch 43, Loss: 2.411038218789976e-05\n",
      "Epoch 43, Loss: 0.1705111563205719\n",
      "MyNN: Epoch 44, Loss: 2.647863426812468e-07\n",
      "KNN: Epoch 44, Loss: 2.3201310884277618e-05\n",
      "Epoch 44, Loss: 0.1649034470319748\n",
      "MyNN: Epoch 45, Loss: 2.4341711029764673e-07\n",
      "KNN: Epoch 45, Loss: 2.240959564783514e-05\n",
      "Epoch 45, Loss: 0.16039973497390747\n",
      "MyNN: Epoch 46, Loss: 2.241302472795711e-07\n",
      "KNN: Epoch 46, Loss: 2.1675053387344592e-05\n",
      "Epoch 46, Loss: 0.15677598118782043\n",
      "MyNN: Epoch 47, Loss: 2.066905530062814e-07\n",
      "KNN: Epoch 47, Loss: 2.098597239777722e-05\n",
      "Epoch 47, Loss: 0.15385083854198456\n",
      "MyNN: Epoch 48, Loss: 1.908924624730949e-07\n",
      "KNN: Epoch 48, Loss: 2.033089805993243e-05\n",
      "Epoch 48, Loss: 0.1514783501625061\n",
      "MyNN: Epoch 49, Loss: 1.7655606254348595e-07\n",
      "KNN: Epoch 49, Loss: 1.9708080171866187e-05\n",
      "Epoch 49, Loss: 0.14954164624214172\n",
      "MyNN: Epoch 50, Loss: 1.6352359687861586e-07\n",
      "KNN: Epoch 50, Loss: 1.9116194548200586e-05\n",
      "Epoch 50, Loss: 0.14794787764549255\n",
      "MyNN: Epoch 51, Loss: 1.51656484767556e-07\n",
      "KNN: Epoch 51, Loss: 1.855329259551426e-05\n",
      "Epoch 51, Loss: 0.146622896194458\n",
      "MyNN: Epoch 52, Loss: 1.408327718080853e-07\n",
      "KNN: Epoch 52, Loss: 1.8017526602639343e-05\n",
      "Epoch 52, Loss: 0.14550824463367462\n",
      "MyNN: Epoch 53, Loss: 1.3094494487836948e-07\n",
      "KNN: Epoch 53, Loss: 1.7507185901363304e-05\n",
      "Epoch 53, Loss: 0.14455796778202057\n",
      "MyNN: Epoch 54, Loss: 1.2189805550844758e-07\n",
      "KNN: Epoch 54, Loss: 1.7020685827726488e-05\n",
      "Epoch 54, Loss: 0.14373598992824554\n",
      "MyNN: Epoch 55, Loss: 1.1360810512465599e-07\n",
      "KNN: Epoch 55, Loss: 1.6635206226782347e-05\n",
      "Epoch 55, Loss: 0.1430143415927887\n",
      "MyNN: Epoch 56, Loss: 1.06000653240859e-07\n",
      "KNN: Epoch 56, Loss: 1.6228535435026934e-05\n",
      "Epoch 56, Loss: 0.14237049221992493\n",
      "MyNN: Epoch 57, Loss: 9.900961588719636e-08\n",
      "KNN: Epoch 57, Loss: 1.583717889267206e-05\n",
      "Epoch 57, Loss: 0.1417873203754425\n",
      "MyNN: Epoch 58, Loss: 9.257622669094384e-08\n",
      "KNN: Epoch 58, Loss: 1.5427321930375915e-05\n",
      "Epoch 58, Loss: 0.14125125110149384\n",
      "MyNN: Epoch 59, Loss: 8.664813727199462e-08\n",
      "KNN: Epoch 59, Loss: 1.5110520942187919e-05\n",
      "Epoch 59, Loss: 0.14075176417827606\n",
      "MyNN: Epoch 60, Loss: 8.117863715551603e-08\n",
      "KNN: Epoch 60, Loss: 1.476113927924488e-05\n",
      "Epoch 60, Loss: 0.1402808278799057\n",
      "MyNN: Epoch 61, Loss: 7.612597637129502e-08\n",
      "KNN: Epoch 61, Loss: 1.4424024148378085e-05\n",
      "Epoch 61, Loss: 0.1398320496082306\n",
      "MyNN: Epoch 62, Loss: 7.145277640021479e-08\n",
      "KNN: Epoch 62, Loss: 1.4099043530664465e-05\n",
      "Epoch 62, Loss: 0.1394006311893463\n",
      "MyNN: Epoch 63, Loss: 6.7125517230321e-08\n",
      "KNN: Epoch 63, Loss: 1.3753198803233152e-05\n",
      "Epoch 63, Loss: 0.13898280262947083\n",
      "MyNN: Epoch 64, Loss: 6.311409006436548e-08\n",
      "KNN: Epoch 64, Loss: 1.3493390779326518e-05\n",
      "Epoch 64, Loss: 0.13857567310333252\n",
      "MyNN: Epoch 65, Loss: 5.9391406725966173e-08\n",
      "KNN: Epoch 65, Loss: 1.3201418982046121e-05\n",
      "Epoch 65, Loss: 0.13817700743675232\n",
      "MyNN: Epoch 66, Loss: 5.5931242430855376e-08\n",
      "KNN: Epoch 66, Loss: 1.2919141023312768e-05\n",
      "Epoch 66, Loss: 0.13778503239154816\n",
      "MyNN: Epoch 67, Loss: 5.2702781517400466e-08\n",
      "KNN: Epoch 67, Loss: 1.2646344407364314e-05\n",
      "Epoch 67, Loss: 0.13739843666553497\n",
      "MyNN: Epoch 68, Loss: 4.9683630611297886e-08\n",
      "KNN: Epoch 68, Loss: 1.2381359741207188e-05\n",
      "Epoch 68, Loss: 0.137016162276268\n",
      "MyNN: Epoch 69, Loss: 4.685872886898989e-08\n",
      "KNN: Epoch 69, Loss: 1.2100402013816172e-05\n",
      "Epoch 69, Loss: 0.13663747906684875\n",
      "MyNN: Epoch 70, Loss: 4.421416023808916e-08\n",
      "KNN: Epoch 70, Loss: 1.1885107341735971e-05\n",
      "Epoch 70, Loss: 0.13626182079315186\n",
      "MyNN: Epoch 71, Loss: 4.173712300764916e-08\n",
      "KNN: Epoch 71, Loss: 1.16450403259019e-05\n",
      "Epoch 71, Loss: 0.13588875532150269\n",
      "MyNN: Epoch 72, Loss: 3.941582533178936e-08\n",
      "KNN: Epoch 72, Loss: 1.1411858287803635e-05\n",
      "Epoch 72, Loss: 0.13551771640777588\n",
      "MyNN: Epoch 73, Loss: 3.723939357667171e-08\n",
      "KNN: Epoch 73, Loss: 1.1185634908399944e-05\n",
      "Epoch 73, Loss: 0.13514851033687592\n",
      "MyNN: Epoch 74, Loss: 3.519779115342799e-08\n",
      "KNN: Epoch 74, Loss: 1.096608096932283e-05\n",
      "Epoch 74, Loss: 0.1347808837890625\n",
      "MyNN: Epoch 75, Loss: 3.328174616719765e-08\n",
      "KNN: Epoch 75, Loss: 1.0733365526223464e-05\n",
      "Epoch 75, Loss: 0.13441476225852966\n",
      "MyNN: Epoch 76, Loss: 3.148268657752191e-08\n",
      "KNN: Epoch 76, Loss: 1.0552912420618323e-05\n",
      "Epoch 76, Loss: 0.13405001163482666\n",
      "MyNN: Epoch 77, Loss: 2.97926818305566e-08\n",
      "KNN: Epoch 77, Loss: 1.035209894128233e-05\n",
      "Epoch 77, Loss: 0.13368649780750275\n",
      "MyNN: Epoch 78, Loss: 2.8204390122414298e-08\n",
      "KNN: Epoch 78, Loss: 1.0156728957709185e-05\n",
      "Epoch 78, Loss: 0.1333240419626236\n",
      "MyNN: Epoch 79, Loss: 2.6711010603947918e-08\n",
      "KNN: Epoch 79, Loss: 9.96690115320989e-06\n",
      "Epoch 79, Loss: 0.13296262919902802\n",
      "MyNN: Epoch 80, Loss: 2.5306239952437226e-08\n",
      "KNN: Epoch 80, Loss: 9.782597225767698e-06\n",
      "Epoch 80, Loss: 0.13260222971439362\n",
      "MyNN: Epoch 81, Loss: 2.398423282659037e-08\n",
      "KNN: Epoch 81, Loss: 9.586170627792397e-06\n",
      "Epoch 81, Loss: 0.132242813706398\n",
      "MyNN: Epoch 82, Loss: 2.2739565791801847e-08\n",
      "KNN: Epoch 82, Loss: 9.435051052106368e-06\n",
      "Epoch 82, Loss: 0.13188432157039642\n",
      "MyNN: Epoch 83, Loss: 2.1567204360510268e-08\n",
      "KNN: Epoch 83, Loss: 9.265922341269792e-06\n",
      "Epoch 83, Loss: 0.13152673840522766\n",
      "MyNN: Epoch 84, Loss: 2.0462472838855214e-08\n",
      "KNN: Epoch 84, Loss: 9.101155519338237e-06\n",
      "Epoch 84, Loss: 0.13117001950740814\n",
      "MyNN: Epoch 85, Loss: 1.942102670845622e-08\n",
      "KNN: Epoch 85, Loss: 8.940589430767378e-06\n",
      "Epoch 85, Loss: 0.1308141052722931\n",
      "MyNN: Epoch 86, Loss: 1.84388273051548e-08\n",
      "KNN: Epoch 86, Loss: 8.78418397582919e-06\n",
      "Epoch 86, Loss: 0.13045896589756012\n",
      "MyNN: Epoch 87, Loss: 1.7512118582763296e-08\n",
      "KNN: Epoch 87, Loss: 8.606420633900795e-06\n",
      "Epoch 87, Loss: 0.13010470569133759\n",
      "MyNN: Epoch 88, Loss: 1.663740577310671e-08\n",
      "KNN: Epoch 88, Loss: 8.468449473704833e-06\n",
      "Epoch 88, Loss: 0.12975136935710907\n",
      "MyNN: Epoch 89, Loss: 1.5811435773716275e-08\n",
      "KNN: Epoch 89, Loss: 8.313218585630358e-06\n",
      "Epoch 89, Loss: 0.12939885258674622\n",
      "MyNN: Epoch 90, Loss: 1.503117911123072e-08\n",
      "KNN: Epoch 90, Loss: 8.158466974838888e-06\n",
      "Epoch 90, Loss: 0.1290472149848938\n",
      "MyNN: Epoch 91, Loss: 1.429381334396087e-08\n",
      "KNN: Epoch 91, Loss: 8.004845833562236e-06\n",
      "Epoch 91, Loss: 0.12869638204574585\n",
      "MyNN: Epoch 92, Loss: 1.3596707780264713e-08\n",
      "KNN: Epoch 92, Loss: 7.855707482237276e-06\n",
      "Epoch 92, Loss: 0.12834635376930237\n",
      "MyNN: Epoch 93, Loss: 1.2937409400810501e-08\n",
      "KNN: Epoch 93, Loss: 7.710998441538293e-06\n",
      "Epoch 93, Loss: 0.12799718976020813\n",
      "MyNN: Epoch 94, Loss: 1.2313629883805851e-08\n",
      "KNN: Epoch 94, Loss: 7.554932354573234e-06\n",
      "Epoch 94, Loss: 0.12764883041381836\n",
      "MyNN: Epoch 95, Loss: 1.1723233640714516e-08\n",
      "KNN: Epoch 95, Loss: 7.436962118867104e-06\n",
      "Epoch 95, Loss: 0.12730126082897186\n",
      "MyNN: Epoch 96, Loss: 1.1164226779043645e-08\n",
      "KNN: Epoch 96, Loss: 7.304177935914473e-06\n",
      "Epoch 96, Loss: 0.12695449590682983\n",
      "MyNN: Epoch 97, Loss: 1.0634746915812348e-08\n",
      "KNN: Epoch 97, Loss: 7.174746934613081e-06\n",
      "Epoch 97, Loss: 0.12660862505435944\n",
      "MyNN: Epoch 98, Loss: 1.013305377233679e-08\n",
      "KNN: Epoch 98, Loss: 7.048805442925898e-06\n",
      "Epoch 98, Loss: 0.1262635439634323\n",
      "MyNN: Epoch 99, Loss: 9.657520486592794e-09\n",
      "KNN: Epoch 99, Loss: 6.926251095084427e-06\n",
      "Epoch 99, Loss: 0.12591956555843353\n",
      "MyNN: Epoch 100, Loss: 9.20662558553049e-09\n",
      "KNN: Epoch 100, Loss: 6.806958711317661e-06\n",
      "Epoch 100, Loss: 0.12557636201381683\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit_sum_experiment(\n",
    "    input_size=5,\n",
    "    learning_rate=0.01,\n",
    "    training_steps=100,\n",
    "    training_data_size=1000,\n",
    "    layer_sizes=[10, ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm so kinda working?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
